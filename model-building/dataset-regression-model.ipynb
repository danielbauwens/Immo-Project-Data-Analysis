{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5723659342026273\n",
      "Testing score: 0.6288733523806418\n",
      "Using 124 features, and 1 (price)target\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Reading our Immoweb dataset in 'df'.\n",
    "df = pd.read_csv('../data/merged_data.csv')\n",
    "\n",
    "# Instantiating LinearRegression as 'reg'.\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Filling NaN values with 0.\n",
    "df['landplot'].fillna(0, inplace=True)\n",
    "df['facades'].fillna(0, inplace=True)\n",
    "df['Living area'].fillna(0, inplace=True)\n",
    "\n",
    "# Reduces zip codes to 2 digits for broader scope.\n",
    "df['Zip code'] = (df['Zip code']/100).astype(int)\n",
    "\n",
    "# Creating dummy columns from categorical data.\n",
    "df = pd.get_dummies(df, columns=['condition', 'province', 'subtype', 'Zip code'])\n",
    "\n",
    "# Removing features that we won't be using.\n",
    "df.drop(['city', 'Kitchen', 'Terrace', 'type'], axis=1, inplace=True)\n",
    "\n",
    "# Because 'get_dummies()' creates boolean values, we re-define our dataframe to be integers only.\n",
    "df = df.astype(int)\n",
    "\n",
    "# Shows the 10 first rows of the cleaned dataframe.\n",
    "#display(df.head(10))\n",
    "\n",
    "# Defining 'X' and 'y' variables from our dataframe using purely features that contain numerical data.\n",
    "X = df.drop(['price'], axis=1).to_numpy()\n",
    "y = df['price'].to_numpy()\n",
    "\n",
    "# Reshaping 'y' to be 2D array.\n",
    "#y = y.reshape(-1, 1) # Depending on what Regressor is being used, this might need to be commented out.\n",
    "\n",
    "# Setting up 'train_test_split' to get standardized training/testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Training our model.\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Displaying score of Training variables.\n",
    "print(\"Training score:\", reg.score(X_train, y_train)) \n",
    "\n",
    "# Predicting the 'y' target value (Price).\n",
    "y_prediction = reg.predict(X_test)\n",
    "\n",
    "# Displaying the score of Testing variables\n",
    "features = X.shape[1]\n",
    "print(\"Testing score:\", reg.score(X_test, y_test))\n",
    "print(f\"Using {features} features, and 1 (price)target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTR Training score: 0.8545982492127151\n",
      "DTR Testing score: 0.6645508280917023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Instatiate 'DecisionTreeRegressor()' and setting parameters.\n",
    "dtr = DecisionTreeRegressor(max_depth=50, max_leaf_nodes=120)\n",
    "\n",
    "dtr.fit(X_train, y_train)\n",
    "print('DTR Training score:', dtr.score(X_train, y_train))\n",
    "y_pred = dtr.predict(X_test)\n",
    "print('DTR Testing score:', dtr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training score: 0.9448546453096737\n",
      "XGBoost Testing score: 0.8388767187915009\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Attempt at using XGBoost\n",
    "xg = XGBRegressor()\n",
    "\n",
    "xg.fit(X_train, y_train)\n",
    "predictions = xg.predict(X_test)\n",
    "print('XGBoost Training score:', xg.score(X_train, y_train))\n",
    "print('XGBoost Testing score:', xg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Training score: 0.9659689331535662\n",
      "RandomForest Testing score: 0.8412647909427289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rforest = RandomForestRegressor()\n",
    "\n",
    "rforest.fit(X_train, y_train)\n",
    "prd = rforest.predict(X_test)\n",
    "print('RandomForest Training score:', rforest.score(X_train, y_train))\n",
    "print('RandomForest Testing score:', rforest.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysis_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
