# ImmoWeb Data Analysis and Prediction Models

A multi-week project combining our skills with plotting, analyzing and regression models.

## About

This repository includes work done over 2 different projects that will be concluded with a final price predictor project (yet to be added).

### Data Scraper (Part One)
![CSV](./output/csvfile.png)
Pilot project: [our Data Scraper.](https://github.com/danielbauwens/challenge-collecting-data)
The very first project, which can be found in its own repository. 

### Data Analysis (Part Two)
![Data!](./output/output.png)

This was made as the second part of a four part study project, where the aim was to get to know and familiarize ourselves with plotting, data visualizations and making correlatinos between multiple Data entries.

### Data Modelling (Part Three)
![Score](./output/training.png)
This was made as the third part of the study project. The main goal is to understand how to use our datasets with regression machine learning models to predict accurate target values(whatever that may be) based on the inputted features. All the while making sure not to overfit the model to the data at hand.

### Data Prediction (Part Four/Conclusion)
To be completed.

## Installation (and Requirements)

![Python Version](https://img.shields.io/badge/Python-3.xx-orange) ![Requirements](https://img.shields.io/badge/Easy-For_You-gr)

*The two notebooks include the initial graphing results from part one, and the pipeline used to get the scores from LinearRegression, XGBoost, DecisionTree and RandomForest models. The SRC folder only uses the LinearRegressor, which appears to be the weakest in predicting the actual target value.*

For required packages you can use 'pip install -m requirements.txt' in your terminal to get everything.

Run the 'main.py' file with the correctly processed dataset (variable names that match those included in the original 'merged_data.csv' file). Put your dataset in the '/data' directory and link to it with the correct name in the 'dataframe' variable.

![Dataframe](./output/dataframe.png)

## Timeline 

**Part One(*Data Analysis*)** was completed over the course of 5 (work)days, from the 5th of Juli to the 11th of Juli.

**Part Two(*Data Modelling*)** was completed over the course of 4 days, from the 17th of Juli to the 20th of Juli.

## Future Improvements/Additions

### Data Analysis Improvements:
- More accuracy with Data Correlations by having a bigger dataset.
- Can try for wider choice of plots to use (map locations, area charts, ...)
- Better usage of color to highlight specific values

### Data Modelling Improvements:
- Explore different regression models.
- More Parameter Tuning.
- Bigger datasets.
- Cleaner datasets/more pre-processing.

## Related

Here are some related projects by me:

- [Zipcode/City Data scraper I made for this project](https://github.com/danielbauwens/Data-Scraper-Belgian-Locations)
- [First part of this project: I'm using the dataset taken from here.](https://github.com/danielbauwens/challenge-collecting-data)


## About me

You can find more of my work here;

- [Daniel's LinkedIn](https://www.linkedin.com/in/daniel-bauwens-5515a8256/)
- [Daniel's GitHub](https://github.com/danielbauwens)